# Neural-Network
Implementing a neural network from scratch using JAX

What is jax?

Well,
It can differentiate through a large subset of Pythonâ€™s features, including loops, ifs, recursion, and closures, and it can even take derivatives of derivatives of derivatives. It supports reverse-mode as well as forward-mode differentiation, and the two can be composed arbitrarily to any order.

In the above colab, we have made a neural network with two hidden layers, using MNIST Dataset. 
I have explained the code as well as its implementation in the detailed colab.
